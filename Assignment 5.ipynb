{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree(classifier):\n",
    "\n",
    "    def __init__(self, criterion = 'entropy'):\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def gini(self, Y):\n",
    "        size = len(Y)\n",
    "        counts = dict()\n",
    "        for y in Y:\n",
    "            if y not in counts:\n",
    "                counts[y] = 0.\n",
    "            counts[y] += 1.\n",
    "        gini = 0.\n",
    "        for key in counts:\n",
    "            prob = counts[key] / size\n",
    "            gini += prob * (1-prob)\n",
    "        return gini\n",
    "\n",
    "\n",
    "    def entropy(self, Y):\n",
    "        from math import log\n",
    "\n",
    "        size = len(Y)\n",
    "        counts = dict()\n",
    "        for y in Y:\n",
    "            if y not in counts:\n",
    "                counts[y] = 0.\n",
    "            counts[y] += 1.\n",
    "        entropy = 0.\n",
    "        for key in counts:\n",
    "            prob = counts[key] / size\n",
    "            entropy -= prob * log(prob,2)\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def split_data(self, X, Y, axis, value):\n",
    "        return_x = []\n",
    "        return_y = []\n",
    "\n",
    "        for x, y in (zip(X, Y)):\n",
    "            if x[axis] == value:\n",
    "                reduced_x = x[:axis]\n",
    "                reduced_x.extend(x[axis+1:])\n",
    "                return_x.append(reduced_x)\n",
    "                return_y.append(y)\n",
    "        return return_x, return_y\n",
    "\n",
    "\n",
    "    def choose_feature(self, X, Y):\n",
    "        if self.criterion == 'entropy':\n",
    "#             print(\"Entropy\")\n",
    "            entropy = self.entropy(Y)\n",
    "            best_information_gain = 0.\n",
    "            best_feature = -1\n",
    "            for i in range(len(X[0])):  # For each feature\n",
    "                feature_list = [x[i] for x in X]\n",
    "                values = set(feature_list)\n",
    "                entropy_i = 0.\n",
    "                for value in values:\n",
    "                    sub_x, sub_y = self.split_data(X, Y, i, value)\n",
    "                    prob = len(sub_x) / float(len(X))\n",
    "                    entropy_i += prob * self.entropy(sub_y)\n",
    "                info_gain = entropy - entropy_i\n",
    "                if info_gain > best_information_gain:\n",
    "                    best_information_gain = info_gain\n",
    "                    best_feature = i\n",
    "            return best_feature\n",
    "        else:\n",
    "#             print(\"Gini\")\n",
    "            entropy = self.gini(Y)\n",
    "            best_information_gain = 0.\n",
    "            best_feature = -1\n",
    "            for i in range(len(X[0])):  # For each feature\n",
    "                feature_list = [x[i] for x in X]\n",
    "                values = set(feature_list)\n",
    "                entropy_i = 0.\n",
    "                for value in values:\n",
    "                    sub_x, sub_y = self.split_data(X, Y, i, value)\n",
    "                    prob = len(sub_x) / float(len(X))\n",
    "                    entropy_i += prob * self.gini(sub_y)\n",
    "                info_gain = entropy - entropy_i\n",
    "                if info_gain > best_information_gain:\n",
    "                    best_information_gain = info_gain\n",
    "                    best_feature = i\n",
    "            return best_feature\n",
    "\n",
    "\n",
    "    def class_dict(self, Y):\n",
    "        classes = dict()\n",
    "        for y in Y:\n",
    "            if y not in classes:\n",
    "                classes[y] = 0\n",
    "            classes[y] += 1\n",
    "        return classes\n",
    "\n",
    "\n",
    "    def majority(self, Y):\n",
    "        from operator import itemgetter\n",
    "        # Use this function if a leaf cannot be split further and\n",
    "        # ... the node is not pure\n",
    "\n",
    "        classcount = self.class_dict(Y)\n",
    "        sorted_classcount = sorted(classcount.items(), key=itemgetter(1), reverse=True)\n",
    "        return sorted_classcount[0][0]\n",
    "\n",
    "\n",
    "    def build_tree(self, X, Y):\n",
    "#         print(type(X), type(Y))\n",
    "        # IF there's only one instance or one class, don't continue to split\n",
    "        if len(Y) <= 1 or len(self.class_dict(Y)) == 1:\n",
    "#             print(Y)\n",
    "            return Y[0]\n",
    "\n",
    "        if len(X[0]) == 1:\n",
    "            return self.majority(Y)   # TODO: Fix this\n",
    "\n",
    "        best_feature = self.choose_feature(X, Y)\n",
    "        if best_feature < 0 or best_feature >= len(X[0]):\n",
    "            return self.majority(Y)\n",
    "\n",
    "        this_tree = dict()\n",
    "        feature_values = [example[best_feature] for example in X]\n",
    "        unique_values = set(feature_values)\n",
    "        for value in unique_values:\n",
    "            # Build a node with each unique value:\n",
    "            subtree_x, subtree_y = self.split_data(X, Y, best_feature, value)\n",
    "            if best_feature not in this_tree:\n",
    "                this_tree[best_feature] = dict()\n",
    "            if value not in this_tree[best_feature]:\n",
    "                this_tree[best_feature][value] = 0\n",
    "            this_tree[best_feature][value] = self.build_tree(subtree_x, subtree_y)\n",
    "        return this_tree\n",
    "\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.fittedTree = self.build_tree(X, Y)\n",
    "        return self.fittedTree\n",
    "\n",
    "    def predict(self, X):\n",
    "        lista = []\n",
    "        for i in range(len(X)):\n",
    "            val = self.recursivecall(X[i], self.fittedTree)\n",
    "            lista.append(val)\n",
    "        return lista\n",
    "        \n",
    "    def recursivecall(self, X, tree):\n",
    "        try:\n",
    "            if isinstance(tree,int):\n",
    "                return tree\n",
    "            if not isinstance(tree,dict):\n",
    "                return tree\n",
    "            keys = tree.keys()\n",
    "            for k in keys:\n",
    "                a = X[k]\n",
    "                if isinstance(tree[k],dict):\n",
    "                    newtree = tree[k][a]\n",
    "                    return self.recursivecall(X, newtree)\n",
    "                else:\n",
    "                    return tree[k]\n",
    "        except:\n",
    "            return ' <=50K.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "from classifier import classifier\n",
    "from collections import defaultdict\n",
    "\n",
    "class randomforest(classifier):\n",
    "    def __init__(self, trees = 10, max_depth = -1):\n",
    "        self.trees = trees\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, Y, num_trees):\n",
    "        tree_list = create_list(num_trees)  # decision_tree list\n",
    "        for t in tree_list:\n",
    "            subsample_x, subsample_y = subsample(X, Y) # Bagging\n",
    "            feature_list = sample_of_features(X) # Random features\n",
    "            t.fit(subsample_x, subsample_y, feature_list)\n",
    " \n",
    "    def predict(self, X):\n",
    "        hypothesis_list = [t.predict(X) for t in tree_list]\n",
    "        counts = defaultdict(int)\n",
    "        for h in hypothesis_list:\n",
    "            counts[h] += 1\n",
    "        return sorted(counts.items(), reverse=True, key=lambda tup: tup[1])[:len(tree_list)][0][0]\n",
    "    \n",
    "    def subsample(self, X, Y):\n",
    "        x = np.random.randint(0, len(X), size = 50)\n",
    "        return X[x], Y[x]\n",
    " \n",
    "    def sample_of_features(self, X):\n",
    "        print(len(X[1]))\n",
    "        x = np.random.choice(0, len(X[1]), size = 2, replace = False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"adulttrain.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educationNum</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalGain</th>\n",
       "      <th>capitalLoss</th>\n",
       "      <th>hoursPerWeek</th>\n",
       "      <th>nativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  educationNum  \\\n",
       "0   39          State-gov   77516   Bachelors            13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors            13   \n",
       "\n",
       "         maritalStatus        occupation    relationship    race    sex  \\\n",
       "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
       "\n",
       "   capitalGain  capitalLoss  hoursPerWeek   nativeCountry  Income  \n",
       "0         2174            0            40   United-States   <=50K  \n",
       "1            0            0            13   United-States   <=50K  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['age','workclass', 'fnlwgt', 'education', 'educationNum', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex', 'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'Income']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (20.6, 40.2]\n",
       "1        (0.902, 20.6]\n",
       "2         (20.6, 40.2]\n",
       "3         (20.6, 40.2]\n",
       "4         (20.6, 40.2]\n",
       "5         (20.6, 40.2]\n",
       "6        (0.902, 20.6]\n",
       "7         (40.2, 59.8]\n",
       "8         (40.2, 59.8]\n",
       "9         (20.6, 40.2]\n",
       "10        (79.4, 99.0]\n",
       "11        (20.6, 40.2]\n",
       "12        (20.6, 40.2]\n",
       "13        (40.2, 59.8]\n",
       "14        (20.6, 40.2]\n",
       "15        (40.2, 59.8]\n",
       "16        (20.6, 40.2]\n",
       "17        (20.6, 40.2]\n",
       "18        (40.2, 59.8]\n",
       "19        (40.2, 59.8]\n",
       "20        (59.8, 79.4]\n",
       "21       (0.902, 20.6]\n",
       "22        (20.6, 40.2]\n",
       "23        (20.6, 40.2]\n",
       "24        (20.6, 40.2]\n",
       "25        (20.6, 40.2]\n",
       "26        (20.6, 40.2]\n",
       "27        (59.8, 79.4]\n",
       "28        (79.4, 99.0]\n",
       "29        (20.6, 40.2]\n",
       "             ...      \n",
       "32531     (79.4, 99.0]\n",
       "32532     (59.8, 79.4]\n",
       "32533     (40.2, 59.8]\n",
       "32534     (20.6, 40.2]\n",
       "32535     (20.6, 40.2]\n",
       "32536     (40.2, 59.8]\n",
       "32537     (40.2, 59.8]\n",
       "32538     (40.2, 59.8]\n",
       "32539    (0.902, 20.6]\n",
       "32540     (20.6, 40.2]\n",
       "32541     (20.6, 40.2]\n",
       "32542     (20.6, 40.2]\n",
       "32543     (40.2, 59.8]\n",
       "32544     (20.6, 40.2]\n",
       "32545    (0.902, 20.6]\n",
       "32546     (20.6, 40.2]\n",
       "32547     (20.6, 40.2]\n",
       "32548     (59.8, 79.4]\n",
       "32549     (20.6, 40.2]\n",
       "32550     (40.2, 59.8]\n",
       "32551     (20.6, 40.2]\n",
       "32552     (40.2, 59.8]\n",
       "32553    (0.902, 20.6]\n",
       "32554     (20.6, 40.2]\n",
       "32555     (20.6, 40.2]\n",
       "32556     (20.6, 40.2]\n",
       "32557     (20.6, 40.2]\n",
       "32558     (20.6, 40.2]\n",
       "32559    (0.902, 20.6]\n",
       "32560     (20.6, 40.2]\n",
       "Name: hoursPerWeek, Length: 32561, dtype: category\n",
       "Categories (5, interval[float64]): [(0.902, 20.6] < (20.6, 40.2] < (40.2, 59.8] < (59.8, 79.4] < (79.4, 99.0]]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = df.iloc[:,0]\n",
    "pd.cut(age, 5)\n",
    "\n",
    "fnlwgt = df.iloc[:,2]\n",
    "pd.cut(fnlwgt, 5)\n",
    "\n",
    "educationNum = df.iloc[:,4]\n",
    "pd.cut(educationNum, 5)\n",
    "\n",
    "capitalGain = df.iloc[:,10]\n",
    "pd.cut(capitalGain, 5)\n",
    "\n",
    "capitalLoss = df.iloc[:,11]\n",
    "pd.cut(capitalLoss, 5)\n",
    "\n",
    "hoursPerWeek = df.iloc[:,12]\n",
    "pd.cut(hoursPerWeek, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.iloc[:,:-1]\n",
    "train_labels = df.iloc[:,-1]\n",
    "\n",
    "train_data = train_data.values.tolist()\n",
    "train_labels = train_labels.values.tolist()\n",
    "\n",
    "decision = decision_tree()\n",
    "\n",
    "tree  = decision.fit(train_data, train_labels)\n",
    "# print('Tree :',tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.44324324324324327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dftest = pd.read_csv(\"adulttest.csv\")\n",
    "dftest.columns = ['age','workclass', 'fnlwgt', 'education', 'educationNum', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex', 'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'Income']\n",
    "dftest.head(2)\n",
    "\n",
    "test_data = dftest.iloc[:,:-1]\n",
    "test_labels = dftest.iloc[:,-1]\n",
    "\n",
    "test_data = test_data.values.tolist()\n",
    "test_labels = test_labels.values.tolist()\n",
    "\n",
    "hyp = decision.predict(test_data)\n",
    "# print(test_labels)\n",
    "# print(hyp)\n",
    "\n",
    "print('Accuracy : ', accuracy_score(test_labels,hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = randomforest()\n",
    "print(randomforest.sample_of_features(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
